{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources while maintaining consistency in their content.\n",
      "2. **Product Design**: Generative AI can aid in the design of products such as furniture, electronics, and other consumer goods. It can generate multiple designs based on specifications and customer feedback, reducing design time and cost.\n",
      "3. **Image and Video Generation**: Generative AI can create high-quality images and videos for marketing, advertising, and social media platforms. This can help businesses create engaging content without the need for expensive photography or videography services.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants that provide customer support, answer frequently asked questions, and offer product recommendations.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from machines to predict when maintenance is required, reducing downtime and increasing overall efficiency.\n",
      "6. **Risk Analysis**: Generative AI can help identify potential risks in financial markets by analyzing large amounts of data and predicting market trends.\n",
      "7. **Customer Segmentation**: Generative AI can segment customers based on their behavior, preferences, and demographics, helping businesses tailor their marketing efforts to specific groups.\n",
      "8. **Email Marketing**: Generative AI can create personalized email campaigns that are tailored to individual recipients' interests and behavior.\n",
      "9. **Language Translation**: Generative AI can help translate languages in real-time, breaking down language barriers for businesses operating globally.\n",
      "10. **Music and Audio Generation**: Generative AI can create original music, sound effects, and audio tracks for film, television, and video games.\n",
      "11. **Fashion Design**: Generative AI can generate new fashion designs based on trends, customer feedback, and product requirements, reducing design time and cost.\n",
      "12. **Architecture and Urban Planning**: Generative AI can aid in the design of buildings, cities, and infrastructure projects by generating multiple design options based on specifications and constraints.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses emerge.\n",
      "\n",
      "**Benefits of Generative AI:**\n",
      "\n",
      "1. Increased efficiency and productivity\n",
      "2. Improved customer experience through personalized content and support\n",
      "3. Enhanced creativity and innovation in product design and marketing\n",
      "4. Reduced costs associated with manual content creation and design\n",
      "5. Ability to analyze large amounts of data and make predictions\n",
      "\n",
      "However, it's essential to note that Generative AI also raises concerns around:\n",
      "\n",
      "1. Data privacy and security\n",
      "2. Bias and fairness in AI decision-making\n",
      "3. Job displacement for humans in certain industries\n",
      "4. Dependence on technology and lack of human judgment\n",
      "\n",
      "To ensure a successful implementation of Generative AI, businesses must carefully consider these factors and develop strategies to mitigate any negative impacts.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to describe some business applications of Generative AI. Hmm, I'm not exactly sure where to start, but I know that generative AI is like creating content automatically using AI models, right? It's different from other AI uses, like customer service, which I remember reading about before.\n",
      "\n",
      "Let me think... Maybe marketing is one area because it often needs a lot of content. Companies have to create promotional materials, ads, maybe even blogs or customer communications. If Generative AI can write text, that could save them a lot of time by automatically generating content that's consistent with their brand.\n",
      "\n",
      "Another possibility is creative industries. Artists and designers might use it to generate new ideas quickly, like in fashion or graphic design. It could help with concept generation for products or even art pieces without needing human creativity at every step.\n",
      "\n",
      "E-commerce comes to mind too. A customer-facing website needs lots of product descriptions, images, and maybe even suggestions on what to buy next. Generative AI could create those product descriptions automatically, making the shopping experience more seamless for customers.\n",
      "\n",
      "Education might benefit from it as well, especially in content creation. Teachers could generate quizzes or exams, course materials, which would save them a lot of time. Additionally, students could get personalized practice problems based on their performance using AI models that analyze data.\n",
      "\n",
      "HR is another area where AI could shine. Talent scouting programs and employee onboarding might use generative AI to create training modules or tailor hiring practices. It could also help in generating job descriptions based on the company's needs without going through lengthy hiring processes.\n",
      "\n",
      "Customer service might see an improvement too, but instead of just answering questions, it could help generate FAQs from common user queries or even empathy maps that understand users' pain points better. That could enhance how companies support their customers by providing more accurate and empathetic responses.\n",
      "\n",
      "Cities and urban planning could use generative AI for generating layouts for new neighborhoods or transportation systems. By simulating different scenarios based on data, it can help in making informed decisions about infrastructure without having to build each possibility physically.\n",
      "\n",
      "Law is interesting too. Legal documents like wills, contracts, or lawsuits might be generated automatically with proper legal jargon and structure. This could reduce the time and resources needed by law firms while also decreasing the risk of human error.\n",
      "\n",
      "Marketing campaigns often benefit from creating highly visual content for social media or TV ads. Using generative AI can make the design process faster and more creative, allowing companies to execute campaigns more efficiently without relying solely on human designers.\n",
      "\n",
      "I think I've covered a good list. Now, maybe some of these areas have overlapping applications? For example, marketing uses text generation as well as visual content creation. But overall, each sector seems distinct but capable of utilizing generative AI in specific ways. I should structure my answer by listing each application with brief explanations to clearly show how Generative AI can be applied across various industries.\n",
      "</think>\n",
      "\n",
      "Generative AI offers transformative opportunities across diverse industries by automating and enhancing content creation, creativity, efficiency, and innovation. Here's a structured overview of its applications:\n",
      "\n",
      "1. **Marketing**: \n",
      "   - **Content Generation**: Automatically generates advertising campaigns, product descriptions, and blog posts to maintain consistency with brand messaging, saving time and resources.\n",
      "   - **Customer Communication**: Assists in drafting personalized messages and newsletters, enhancing customer engagement through tailored communication.\n",
      "\n",
      "2. **Creative Industries**:\n",
      "   - **Design Assistance**: Provides rapid design iterations for fashion, architecture, and digital art, accelerating creative exploration while maintaining brand identity.\n",
      "   - **Text Generation**: Helps writers explore new narratives or styles by offering diverse content ideas without the need for manual creation each time.\n",
      "\n",
      "3. **E-commerce**:\n",
      "   - **Product Descriptions**: Generates detailed product descriptions that capture imagination and interest, making online shopping more engaging and seamless for users.\n",
      "   - **Image Synthesis**: Creates high-quality, consistent images across different product categories to enhance online product listings.\n",
      "\n",
      "4. **Education**:\n",
      "   - **Content Creation**: Facilitates the rapid production of quizzes, exams, tutorials, and dynamic problems that adapt to student performance, personalizing learning experiences.\n",
      "\n",
      "5. **Human Resources**:\n",
      "   - **Talent scouting and Onboarding**: Develops tailored training modules and employee onboarding materials that align with individual skills when a human completes them.\n",
      "   - **Job Descriptions**: Creates accurate job postings based on organizational needs without extensive hiring processes or legal expertise.\n",
      "\n",
      "6. **Customer Service**:\n",
      "   - **FAQ Generation**: Uses user interaction data to generate relevant FAQs, reducing repetitive inquiries in customer support systems.\n",
      "   - **Empathy Mapping**: Analyzes and understands customer pain points through empathy maps derived from language patterns, enhancing support strategies with insights.\n",
      "\n",
      "7. **Urban Planning and Cities**:\n",
      "   - **Infrastructure Simulation**: Generates potential city layouts based on population trends or existing infrastructure to help make informed urban development decisions.\n",
      "\n",
      "8. **Legal**:\n",
      "   - **Document Generation**: Automatically creates legal documents such as wills, contracts, and court cases from input data, reducing human error and saving time.\n",
      "   - **Legal Briefing Support**: Helps draft court briefs by analyzing legal precedents and applying them to specific cases with minimal direct involvement.\n",
      "\n",
      "9. **Marketing Campaigns**:\n",
      "   - **Visual Media Creation**: Accelerates the design process for ads, TV spots, and social media content through intelligent algorithms that suggest creative solutions based on target themes or themes, enhancing campaign execution efficiency.\n",
      "\n",
      "Generative AI's versatility lies in its ability to augment creativity, streamline processes, and provide insights across industries. Its applications in marketing, education, law, urban planning, customer service, fashion, e-commerce, human resources, legal, and content creation each offer unique benefits that enhance productivity and innovation by leveraging automated content generation while respecting creative intent.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "MODEL = 'deepseek-r1'\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 96c415656d37... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 4.7 GB                         \n",
      "pulling 369ca498f347... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  387 B                         \n",
      "pulling 6e4c38e1172f... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  148 B                         \n",
      "pulling 40fb844194b2... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand the core concepts behind Large Language Models (LLMs). From what I gathered earlier, there are three main ideas: neural networks, attention mechanisms, and transformers. Let me break each of these down step by step because some parts still feel a bit fuzzy.\n",
      "\n",
      "Starting with neural networks. I know they're a type of machine learning model inspired by the human brain. They consist of layers of interconnected nodes. The input layer receives data, then hidden layers process it, and finally the output layer gives predictions or decisions. Each connection has weights that get adjusted during training. But wait, how exactly do these networks learn? Is it through a process called backpropagation where they adjust weights based on errors?\n",
      "\n",
      "Moving on to attention mechanisms. I've heard this term in the context of neural machine translation and LLMs. From the definition, attention allows the model to focus on different parts of the input when processing each element. So for example, when translating a sentence, each word might pay attention to other words it's related to. But how does this mechanism work technically? It involves calculating some sort of scores that represent the relevance or importance of one part of the input over another. These scores determine how much each element contributes to the output at each step.\n",
      "\n",
      "Now, transformers. The transformer architecture is supposed to handle sequential data more efficiently than traditional RNNs by using self-attention mechanisms. Instead of processing elements sequentially with loops, each position in the sequence can attend to all other positions simultaneously. This parallelism should make training faster and maybe even improve performance by capturing long-range dependencies better.\n",
      "\n",
      "Wait, but how does a transformer differ from a standard neural network? It uses multi-head attention, right? Each head processes different aspects of the data, creating more flexibility. There's also something called feed-forward networks involved in between the attention layers. So each layer has a self-attention part followed by a feed-forward part.\n",
      "\n",
      "Oh, and normalization and layer normalization—these are techniques used within transformers to stabilize training by normalizing the outputs of layers. It helps prevent the gradients from exploding or vanishing, which can make training more stable and efficient.\n",
      "\n",
      "Putting it all together: LLMs use neural networks with multiple layers, attention mechanisms that let them focus on relevant inputs, and a transformer architecture that reorganizes how data flows through these layers for better efficiency and context handling. This combination enables the model to understand complex relationships in text and generate coherent responses when queried, which is why they're so effective for tasks like writing articles or answering questions.\n",
      "\n",
      "But I'm still a bit unclear on some points. For example, what exactly happens during the training process of an LLM? Do all these components work together automatically, or do I need to know how each part is trained separately? Also, when using attention mechanisms, how are they applied step by step in the model's processing, especially with the multi-head aspect?\n",
      "\n",
      "Another thing is normalization—why is it necessary, and what happens if we don't use it? Maybe without layer normalization, the gradients become unstable as layers go deeper. That could lead to slower training or even divergence of the models. So it must be a crucial component for training stability.\n",
      "\n",
      "I also wonder about the difference between self-attention and cross-attention mechanisms. During text generation, like writing an essay, does the model look at other parts of its previous text as well? Or do other models handle that differently?\n",
      "\n",
      "Overall, I think I have a basic grasp now, but diving deeper into each concept's mathematical underpinnings would help solidify my understanding. Maybe looking at the equations used in attention and transformers would clarify how everything works computationally.\n",
      "</think>\n",
      "\n",
      "**Understanding Large Language Models (LLMs): A Core Concept Overview**\n",
      "\n",
      "Large Language Models (LLMs) are complex machine learning systems inspired by the human brain, designed to understand and generate human language. The core concepts behind these models include neural networks, attention mechanisms, and transformers. Here's a structured breakdown of each:\n",
      "\n",
      "1. **Neural Networks**:\n",
      "   - **Structure**: Comprising layers of interconnected nodes (neurons), including input, hidden, and output layers. Each connection between nodes has associated weights.\n",
      "   - **Learning Process**: Through training data, these networks learn by adjusting weights to minimize prediction errors. This adjustment is facilitated by backpropagation, which propagates error gradients backward through the network.\n",
      "\n",
      "2. **Attention Mechanisms**:\n",
      "   - **Purpose**: Allow models to focus on relevant parts of the input when processing each element, enhancing context understanding.\n",
      "   - **Mechanism**: Calculates scores (e.g., dot product) between elements to determine their relevance. These scores guide how much each element contributes to the output at each step.\n",
      "\n",
      "3. **Transformer Architecture**:\n",
      "   - **Multi-Head Attention**: Uses multiple attention heads to capture different contextual aspects, enhancing the model's flexibility and effectiveness.\n",
      "   - **Feed-Forward Networks**: Follow self-attention layers to process data in a parallel manner, improving efficiency and capturing complex patterns.\n",
      "   - **Training Stability**: Layer normalization stabilizes training by normalizing outputs within each layer, preventing gradient issues.\n",
      "\n",
      "**Integration and Functionality**:\n",
      "- Transformers replace sequential processing with attending processes, enabling parallel computation. This architecture allows models to attend to all positions simultaneously, capturing long-range dependencies more effectively than RNNs or LSTMs.\n",
      "\n",
      "**Practical Considerations**:\n",
      "- **Self vs. Cross Attention**: Self-attention focuses within the input sequence, while cross-attention examines external data (e.g., previous text in generation tasks).\n",
      "- **Training Dynamics**: The training process involves optimizing weights through backpropagation and gradient descent, crucial for learning patterns from data.\n",
      "\n",
      "In summary, LLMs combine neural networks with advanced attention mechanisms and transformer architectures to model sequential data efficiently, enabling them to understand complex texts and generate coherent responses. Further exploration of their mathematical underpinnings would provide deeper insights into their operations.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687f584-6aa5-4e3d-ad8c-97520c468f66",
   "metadata": {},
   "source": [
    "API generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed6c3024-38b1-4028-9854-243eb7733ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "OLLAMA_API_GENERATE = \"http://localhost:11434/api/generate\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41276def-d70f-46ed-8808-30c028381db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMT = \"Why is the sky blue?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef9d8d1e-7ac7-4aff-8b86-dbcd19ebe055",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": PROMT,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd881737-a799-4ca8-9622-14995bdd5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the Earth's atmosphere. Here's a simplified explanation:\n",
      "\n",
      "1. **Sunlight enters the atmosphere**: When sunlight enters the Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\n",
      "2. **Scattering occurs**: These gas molecules scatter the shorter (blue) wavelengths of light more than the longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "3. **Blue light is scattered in all directions**: The blue light is scattered in all directions by the gas molecules, making it visible from any direction.\n",
      "4. **Red light continues straight**: Meanwhile, the longer wavelengths of light (like red and orange) continue to travel in a straight line, with less scattering.\n",
      "5. **Our eyes see the blue light**: From our perspective on the ground, we see the scattered blue light as the dominant color of the sky.\n",
      "\n",
      "This effect is more pronounced during the daytime when the sun is overhead and the atmosphere is clearer. During sunrise and sunset, the light has to travel through more of the atmosphere, which scatters the shorter wavelengths even more, making the sky appear red or orange.\n",
      "\n",
      "It's worth noting that the sky can also appear blue at other times due to atmospheric conditions such as pollution, dust, or water vapor, but this is a result of additional scattering and absorption processes.\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API_GENERATE, json=payload, headers=HEADERS)\n",
    "print(response.json()['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28cbef-4427-48d9-a51e-b35854fe0607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
